syntax = "proto2";
package tzrec.protos;

import "google/protobuf/struct.proto";

message ParameterConstraints {
    // embedding sharding type constraints
    // data_parallel | table_wise | column_wise | row_wise | table_row_wise | table_column_wise | grid_shard
    repeated string sharding_types = 1;
    // embedding compute kernel constraints
    // dense | fused | fused_uvm | fused_uvm_caching | key_value
    repeated string compute_kernels = 2;
}

// LFU: evict_score = access_cnt
message LFU_EvictionPolicy {
}

// LRU: evict_score = 1 / pow((current_iter - last_access_iter), decay_exponent)
message LRU_EvictionPolicy {
    // decay rate is access step
    optional float decay_exponent = 1 [default = 1.0];
}

// DistanceLFU: evict_score = access_cnt / pow((current_iter - last_access_iter), decay_exponent)
message DistanceLFU_EvictionPolicy {
    // decay rate is access step
    optional float decay_exponent = 1 [default = 1.0];
}

message ZeroCollisionHash {
    // zero collision size
    required uint64 zch_size = 1;
    // evict interval steps
    optional uint32 eviction_interval = 2 [default = 5];
    // evict policy
    oneof eviction_policy {
        LFU_EvictionPolicy lfu = 101;
        LRU_EvictionPolicy lru = 102;
        DistanceLFU_EvictionPolicy distance_lfu = 103;
    }
    // lambda function string used to filter incoming ids before update/eviction. experimental feature.
    //        [input: Tensor] the function takes as input a 1-d tensor of unique id counts.
    //        [output1: Tensor] the function returns a boolean_mask or index array of corresponding elements in the input tensor that pass the filter.
    //        [output2: float, Tensor] the function returns the threshold that will be used to filter ids before update/eviction. all values <= this value will be filtered out.
    optional string threshold_filtering_func = 3;
}

message AutoDisEmbedding {
    // number of embedding channels
    required uint32 num_channels = 2;
    // temperature coefficient for softmax
    optional float  temperature = 3 [default = 0.1];
    optional float  keep_prob = 4 [default = 0.8];
}

message MLPEmbedding {
}


message DynamicEmbInitializerArgs {
    // the mode of initialization. NORMAL | TRUNCATED_NORMAL | UNIFORM | CONSTANT
    optional string mode = 1;
    // the mean value for (truncated) normal distributions
    optional float mean = 2 [default = 0.0];
    // the standard deviation for (truncated) normal distributions.
    // default is sqrt(1 / embedding_dim)
    optional float std_dev = 3;
    // the lower bound for uniform/truncated_normal distribution.
    // default is -sqrt(1 / max_capacity)
    optional float lower = 4;
    // the upper bound for uniform/truncated_normal distribution.
    // default is sqrt(1 / max_capacity)
    optional float upper = 5;
    // the constant value for constant initialization.
    optional float value = 6 [default = 0.0];
}

message DynamicEmbFrequencyAdmissionStrategy {
    // minimum frequency threshold for admission
    required uint64 threshold = 1;
    // determine how to initialize the embedding if the key is not admitted.
    optional DynamicEmbInitializerArgs initializer_args = 2;
    // kv counter capacity, if not set, use embedding max_capacity
    optional uint64 counter_capacity = 3;
    // kv counter capacity for each bucket.
    optional uint64 counter_bucket_capacity = 4 [default = 1024];
}

message DynamicEmbedding {
    // arguments for initializing dynamic embedding vector values.
    // default is uniform distribution, and absolute values of upper and lower bound are sqrt(1 / embedding_dim).
    optional DynamicEmbInitializerArgs initializer_args = 1;
    // the initializer args for evaluation mode. default is
    // default is constant initialization with value 0.0.
    optional DynamicEmbInitializerArgs eval_initializer_args = 2;
    // strategy to set the score for each indices in forward and backward per table. TIMESTAMP | STEP | CUSTOMIZED | LFU
    optional string score_strategy = 4 [default = "STEP"];
    // max number of embedding rows
    required uint64 max_capacity = 5;
    // percentage of embedding rows caching on gpu
    optional float cache_load_factor = 6;
    // init number of capacity
    optional uint64 init_capacity_per_rank = 7;
    // init table path
    optional string init_table = 8;
    oneof admission_strategy {
        DynamicEmbFrequencyAdmissionStrategy frequency_admission_strategy = 100;
    }
}

message IdFeature {
    // feature name, e.g. item_id
    required string feature_name = 1;
    // feature input, e.g. item:item_id
    required string expression = 2;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 3;
    // embedding dimension
    required uint32 embedding_dim = 4;
    // number of hash size
    optional uint64 hash_bucket_size = 5;
    // number of id enumerators
    optional uint64 num_buckets = 6;
    // id vocabulary list
    repeated string vocab_list = 7;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 8;
    // id value dimensions, default = 0, when use in seq, default = 1
    // if value_dim = 0, it supports id with multi-value
    optional uint32 value_dim = 9;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value, default value before bucktize
    optional string default_value = 11 [default = ""];
    // fg multi-value separator
    optional string separator = 12 [default = "\x1d"];
    // fg multi-value with whether has weight
    optional bool weighted = 13 [default = false];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 14;
    // mask value in training progress
    optional bool use_mask =  15;
    // zero collision hash
    optional ZeroCollisionHash zch = 16;
    // id vocabulary file path
    optional string vocab_file = 17;
    // vocab file relative directory
    optional string asset_dir = 18;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 19;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // value_type after fg before bucketize, you can specify it for better performance.
    // e.g. fg_value_type = int64 when use num_buckets
    optional string fg_value_type = 32;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message RawFeature {
    // feature name, e.g. click_count
    required string feature_name = 1;
    // feature input, e.g. item:click_count
    required string expression = 2;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 3;
    // embedding dimension
    optional uint32 embedding_dim = 4;
    // boundaries for bucktize numeric feature
    repeated float boundaries = 5;
    // raw feature of multiple dimensions
    optional uint32 value_dim = 6 [default = 1];
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 7;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value
    optional string default_value = 11 [default = "0"];
    // fg multi-value separator
    optional string separator = 12 [default = "\x1d"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 13;
    // mask value in training progress
    optional bool use_mask =  14;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message ComboFeature {
    // feature name, e.g. os_and_cate
    required string feature_name = 1;
    // feature input, e.g. [user:os, item:cate]
    repeated string expression = 2;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 3;
    // embedding dimension
    optional uint32 embedding_dim = 4;
    // number of hash size
    optional uint64 hash_bucket_size = 5;
    // id vocabulary list
    repeated string vocab_list = 7;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 8;
    // id value dimensions, if value_dim = 0, it supports id with multi-value
    optional uint32 value_dim = 9 [default = 0];
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value
    optional string default_value = 11 [default = ""];
    // fg multi-value separator
    optional string separator = 12 [default = "\x1d"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 13;
    // mask value in training progress
    optional bool use_mask =  14;
    // zero collision hash
    optional ZeroCollisionHash zch = 15;
    // id vocabulary file path
    optional string vocab_file = 16;
    // vocab file relative directory
    optional string asset_dir = 17;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 18;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message LookupFeature {
    // feature name, e.g. kv_os_click_count
    required string feature_name = 1;
    // map input, e.g. item:kv_os_click_count
    required string map = 2;
    // key input, e.g. user:os
    required string key = 3;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 4;
    // embedding dimension
    optional uint32 embedding_dim = 5;
    // boundaries for bucktize numeric lookup value
    repeated float boundaries = 6;
    // number of hash size for sparse lookup value
    optional uint64 hash_bucket_size = 7;
    // number of id enumerators for sparse lookup value
    optional uint64 num_buckets = 8;
    // id vocabulary list for sparse lookup value
    repeated string vocab_list = 9;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 10;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 11 [default = "sum"];
    // lookup value combiner type, available is {sum | mean | min | max | count}
    optional string combiner = 12 [default = "sum"];
    // fg default value
    optional string default_value = 13 [default = "0"];
    // fg multi-value separator
    optional string separator = 14 [default = "\x1d"];
    // lookup map value is sparse or numeric,
    // when need_discrete is true, combiner will be empty string
    optional bool need_discrete = 15 [default = false];
    // lookup value need key as prefix or not.
    optional bool need_key = 16 [default = false];
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 17;
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 18;
    // lookup value dimensions
    optional uint32 value_dim = 19;
    // numeric lookup value separator
    optional string value_separator = 20 [default = ","];
    // mask value in training progress
    optional bool use_mask =  21;
    // zero collision hash
    optional ZeroCollisionHash zch = 22;
    // id vocabulary file path
    optional string vocab_file = 23;
    // vocab file relative directory
    optional string asset_dir = 24;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 25;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // value_type after fg before bucketize, you can specify it for better performance.
    // e.g. fg_value_type = int64 when use num_buckets
    optional string fg_value_type = 32;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }

    // TODO: optional string kv_separator = 13 [default = ":"];

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message MatchFeature {
    // feature name, e.g. match_cate_brand_click_count
    required string feature_name = 1;
    // nested map input, e.g. user:match_cate_brand_click_count
    required string nested_map = 2;
    // first layer (primary) key input, e.g. item:cate or ALL
    required string pkey = 3;
    // second layer (secondary) key input, e.g. item:brand or ALL
    required string skey = 4;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 5;
    // embedding dimension
    optional uint32 embedding_dim = 6;
    // boundaries for bucktize numeric match value
    repeated float boundaries = 7;
    // number of hash size for sparse match value
    optional uint64 hash_bucket_size = 8;
    // number of id enumerators for sparse match value
    optional uint64 num_buckets = 9;
    // id vocabulary list for sparse match value
    repeated string vocab_list = 10;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 11;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 12 [default = "sum"];
    // match value combiner type, available is {sum | mean | min | max | count}
    // optional string combiner = 12 [default = "sum"];
    // fg default value
    optional string default_value = 13 [default = "0"];
    // fg multi-value separator
    optional string separator = 14 [default = "\x1d"];
    // match map value is sparse or numeric,
    // when need_discrete is true, combiner will be empty string
    optional bool need_discrete = 15 [default = false];
    // match value need pkey value as prefix or not.
    optional bool show_pkey = 16 [default = false];
    // match value need skey  valueas prefix or not.
    optional bool show_skey = 17 [default = false];
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 18;
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 19;
    // match value dimensions
    optional uint32 value_dim = 20;
    // mask value in training progress
    optional bool use_mask =  21;
    // zero collision hash
    optional ZeroCollisionHash zch = 22;
    // id vocabulary file path
    optional string vocab_file = 23;
    // vocab file relative directory
    optional string asset_dir = 24;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 25;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // value_type after fg before bucketize, you can specify it for better performance.
    // e.g. fg_value_type = int64 when use num_buckets
    optional string fg_value_type = 32;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }
    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message ExprFeature {
    // feature name, e.g. kv_os_click_count
    required string feature_name = 1;
    // expression, e.g. sigmoid(pv/(1+click))
    required string expression = 2;
    // variables in expression, e,g. ["item:pv", "item:click"]
    repeated string variables = 3;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 4;
    // embedding dimension
    optional uint32 embedding_dim = 5;
    // boundaries for bucktize numeric expr value
    repeated float boundaries = 6;
    // fg multi-value separator
    optional string separator = 7 [default = "\x1d"];
    // fill value when vector length mismatch, default is NaN.
    optional float fill_missing = 8;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value
    optional string default_value = 11 [default = "0"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 12;
    // mask value in training progress
    optional bool use_mask =  13;
    // if value_dim = 0, it supports multi-value
    optional uint32 value_dim = 14 [default = 0];

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }
    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message OverlapFeature {
    // feature name, e.g. overlap_ratio
    required string feature_name = 1;
    // query input name, e.g. user:query
    required string query = 2;
    // title input name, e,g. item:title
    required string title = 3;
    // overlap calculate method, available is {query_common_ratio | title_common_ratio | is_contain | is_equal}
    required string method = 4;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 5;
    // embedding dimension
    optional uint32 embedding_dim = 6;
    // boundaries for bucktize numeric expr value
    repeated float boundaries = 7;
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 8;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value
    // optional string default_value = 11 [default = "0"];
    // fg multi-value separator
    optional string separator = 12 [default = "\x1d"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 13;
    // mask value in training progress
    optional bool use_mask =  14;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }
    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}


enum TextNormalizeOption {
    // lower case to upper case
    TEXT_LOWER2UPPER = 0;
    // upper case to lower case
    TEXT_UPPER2LOWER = 1;
    // sbc case to dbc case
    TEXT_SBC2DBC = 2;
    // traditional chinese to simple chinese
    TEXT_CHT2CHS = 3;
    // filter speicial chars
    TEXT_FILTER = 4;
    // chinese split to chars with blanks
    TEXT_SPLITCHRS = 5;
    // remove space
    TEXT_REMOVE_SPACE = 6;
}

message TextNormalizer {
    // if text_length greater than max_length, will not do normalize
    optional uint32 max_length = 1;
    // stop char file path, default will use built-in stop char
    optional string stop_char_file = 2;
    // text normalize options, default is TEXT_LOWER2UPPER & TEXT_SBC2DBC & TEXT_CHT2CHS & TEXT_FILTER
    repeated TextNormalizeOption norm_options = 3;
}

message TokenizeFeature {
    // feature name, e.g. title_token
    required string feature_name = 1;
    // feature input, e.g. item:title
    required string expression = 2;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 3;
    // embedding dimension
    required uint32 embedding_dim = 4;
    // text normalizer
    optional TextNormalizer text_normalizer = 6;
    // tokenizer vocabulary file path
    required string vocab_file = 7;
    // vocab file relative directory
    optional string asset_dir = 8;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value, default value before bucktize
    optional string default_value = 11 [default = ""];
    // tokenizer_type type, available is {bpe | sentencepiece}
    optional string tokenizer_type = 12 [default = "bpe"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 14;
    // mask value in training progress
    optional bool use_mask =  15;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}


message KvDotProduct {
    // feature name, e.g. kv_os_click_count
    required string feature_name = 1;
    // query, e.g. ["a:0.5", "b:0.5"]
    required string query = 2;
    // document, e,g. ["d:0.5", "b:0.5"]
    required string document = 3;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 4;
    // embedding dimension
    optional uint32 embedding_dim = 5;
    // boundaries for bucktize numeric expr value
    repeated float boundaries = 6;
    // fg multi-value separator
    optional string separator = 7 [default = "\x1d"];
    // fg kv separator, default is :.
    optional float kv_delimiter = 8;
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 9;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value
    optional string default_value = 11 [default = "0"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 12;
    // mask value in training progress
    optional bool use_mask = 13;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }
    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message CustomFeature {
    // feature name.
    required string feature_name = 1;
    // custom operator name.
    required string operator_name = 2;
    // custom operator lib file name.
    required string operator_lib_file = 3;
    // operator custom params.
    optional google.protobuf.Struct operator_params = 4;
    // custom operator is thread safe or not.
    optional bool is_op_thread_safe = 5 [default = false];
    // feature input, e.g. user:os
    repeated string expression = 6;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 7;
    // embedding dimension
    optional uint32 embedding_dim = 8;
    // boundaries for bucktize numeric value
    repeated float boundaries = 9;
    // number of hash size for sparse value
    optional uint64 hash_bucket_size = 10;
    // number of id enumerators for sparse value
    optional uint64 num_buckets = 11;
    // id vocabulary list for sparse value
    repeated string vocab_list = 12;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 13;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 14 [default = "sum"];
    // fg default value
    optional string default_value = 15 [default = "0"];
    // fg multi-value separator
    optional string separator = 16 [default = "\x1d"];
    // fg normalizer, e.g.
    // method=log10,threshold=1e-10,default=-10
    // method=zscore,mean=0.0,standard_deviation=10.0
    // method=minmax,min=2.1,max=2.2
    // method=expression,expr=sign(x)
    optional string normalizer = 17;
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 18;
    // value dimensions
    optional uint32 value_dim = 19;
    // mask value in training progress
    optional bool use_mask = 20;
    // zero collision hash
    optional ZeroCollisionHash zch = 21;
    // id vocabulary file path
    optional string vocab_file = 22;
    // vocab file relative directory
    optional string asset_dir = 23;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 24;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    oneof dense_emb {
        // autodis embedding
        AutoDisEmbedding autodis = 40;
        // mlp embedding
        MLPEmbedding mlp = 41;
    }
    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message BoolMaskFeature {
    // feature name.
    required string feature_name = 1;
    // feature input, e.g. item:item_id
    repeated string expression = 2;
    // embedding name, feature with same embedding name will share embedding
    optional string embedding_name = 3;
    // embedding dimension
    required uint32 embedding_dim = 4;
    // number of hash size
    optional uint64 hash_bucket_size = 5;
    // number of id enumerators
    optional uint64 num_buckets = 6;
    // id vocabulary list
    repeated string vocab_list = 7;
    // id vocabulary dict
    map<string, uint64> vocab_dict = 8;
    // id value dimensions, default = 0, when use in seq, default = 1
    // if value_dim = 0, it supports id with multi-value
    optional uint32 value_dim = 9;
    // embedding pooling type, available is {sum | mean}
    optional string pooling = 10 [default = "sum"];
    // fg default value, default value before bucktize
    optional string default_value = 11 [default = ""];
    // fg multi-value separator
    optional string separator = 12 [default = "\x1d"];
    // embedding init function, e.g. "nn.init.uniform_,a=-0.01,b=0.01"
    optional string init_fn = 14;
    // mask value in training progress
    optional bool use_mask =  15;
    // zero collision hash
    optional ZeroCollisionHash zch = 16;
    // id vocabulary file path
    optional string vocab_file = 17;
    // vocab file relative directory
    optional string asset_dir = 18;
    // dynamic embedding
    optional DynamicEmbedding dynamicemb = 19;

    // default value when fg_mode = FG_NONE,
    // when use pai-fg, you do not need to set the param.
    // when use own fg and data contain null value, you can set the param for fill null
    optional string fg_encoded_default_value = 30;
    // out-of-vocab(OOV) id bucketize value when use vocab_list or vocab_dict
    // when use default_bucketize_value, we will not add additional bucketize_value of
    // `default_value`=0, bucketize_value of <OOV>=1 into vocab_list or vocab_dict
    optional uint64 default_bucketize_value = 31;
    // value_type after fg before bucketize, you can specify it for better performance.
    // e.g. fg_value_type = int64 when use num_buckets
    optional string fg_value_type = 32;
    // embedding param trainable or not
    optional bool trainable = 33 [default = true];
    // only used as fg dag intermediate result or not
    optional bool stub_type = 34 [default = false];
    // embedding data type
    optional string data_type = 35 [default = 'FP32'];

    // embedding param constraints
    optional ParameterConstraints embedding_constraints = 50;

    // max sequence length, only take effect when use it as sequence
    required uint32 sequence_length = 101;
    // sequence delimiter, only take effect when use it as sequence
    required string sequence_delim = 102 [default = ";"];
    // specify sequence type fields in inputs. default is item side inputs.
    repeated string sequence_fields = 103;
}

message SequenceFeature {
    // sequence name
    required string sequence_name = 1;
    // max sequence length, only take effect in fg
    required uint32 sequence_length = 2;
    // sequence delimiter
    required string sequence_delim = 3 [default = ";"];
    // sequence primary key name for serving,
    // default will be user:{sequence_name}
    optional string sequence_pk = 4;
    // sub feature config
    repeated SeqFeatureConfig features = 5;
}

message FeatureConfig {
    oneof feature {
        IdFeature id_feature = 1;
        RawFeature raw_feature = 2;
        ComboFeature combo_feature = 3;
        LookupFeature lookup_feature = 4;
        MatchFeature match_feature = 5;
        SequenceFeature sequence_feature = 6;
        ExprFeature expr_feature = 7;
        OverlapFeature overlap_feature = 8;
        TokenizeFeature tokenize_feature = 9;
        CustomFeature custom_feature = 10;
        KvDotProduct kv_dot_product = 11;
        BoolMaskFeature bool_mask_feature = 12;

        IdFeature sequence_id_feature = 101;
        RawFeature sequence_raw_feature = 102;
        ComboFeature sequence_combo_feature = 103;
        LookupFeature sequence_lookup_feature = 104;
        MatchFeature sequence_match_feature = 105;
        ExprFeature sequence_expr_feature = 107;
        OverlapFeature sequence_overlap_feature = 108;
        TokenizeFeature sequence_tokenize_feature = 109;
        CustomFeature sequence_custom_feature = 110;
        KvDotProduct sequence_kv_dot_product = 111;
        BoolMaskFeature sequence_bool_mask_feature = 112;
    }
}


message SeqFeatureConfig {
    oneof feature {
        IdFeature id_feature = 1;
        RawFeature raw_feature = 2;
        ComboFeature combo_feature = 3;
        LookupFeature lookup_feature = 4;
        MatchFeature match_feature = 5;
        ExprFeature expr_feature = 7;
        OverlapFeature overlap_feature = 8;
        TokenizeFeature tokenize_feature = 9;
        CustomFeature custom_feature = 10;
        KvDotProduct kv_dot_product = 11;
        BoolMaskFeature bool_mask_feature = 12;
    }
}
