train_input_path: ""
eval_input_path: ""
model_dir: "experiments/hstu_fg_mock"
train_config {
    sparse_optimizer {
        adam_optimizer {
            lr: 0.001
            weight_decay: 0
            beta1: 0.9
            beta2: 0.98
        }
        constant_learning_rate {
        }
    }
    dense_optimizer {
        adam_optimizer {
            lr: 0.001
            weight_decay: 0
            beta1: 0.9
            beta2: 0.98
        }
        constant_learning_rate {
        }
    }
    num_epochs: 8
}
eval_config {
}
data_config {
    batch_size: 128
    dataset_type: ParquetDataset
    fg_mode: FG_DAG
    label_fields: "clk"
    enable_hstu: true
    num_workers: 8
    negative_sampler {
        input_path: "odps://{PROJECT}/tables/taobao_ad_feature_gl_bucketized_v1"
        num_sample: 128
        attr_fields: "historical_ids"
        item_id_field: "historical_ids"
        attr_delimiter: "\t"
        item_id_delim: ';'
    }
}
feature_configs {
    sequence_id_feature {
        feature_name: "historical_ids"
        sequence_length: 210
        sequence_delim: ";"
        expression: "user:historical_ids"
        num_buckets: 3953
        embedding_dim: 48
    }
}
feature_configs {
    id_feature {
        feature_name: "user_id"
        expression: "user:user_id"
        hash_bucket_size: 1000
        embedding_dim: 48
    }
}
feature_configs {
    id_feature {
        feature_name: "item_id"
        expression: "item:item_id"
        num_buckets: 1000
        embedding_dim: 48
        embedding_name: "item_id"
    }
}

model_config {
    feature_groups {
        group_name: "sequence"
        feature_names: "historical_ids"
        group_type: SEQUENCE
    }
    hstu_match {
        hstu_tower {
            input: 'sequence'
            hstu_encoder: {
                sequence_dim: 48
                attn_dim: 48
                linear_dim: 48
                input: "sequence"
                max_seq_length: 210
                num_blocks: 2
                num_heads: 1
                linear_activation: "silu"
                linear_config: "uvqk"
                max_output_len: 0
            }
        }
        temperature: 0.05
    }
    metrics {
        recall_at_k {
            top_k: 1
        }
    }
    metrics {
        recall_at_k {
            top_k: 5
        }
    }
    losses {
        softmax_cross_entropy {}
    }
}
